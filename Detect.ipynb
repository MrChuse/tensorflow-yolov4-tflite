{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "physical_devices = tf.config.experimental.list_physical_devices('GPU')\n",
    "if len(physical_devices) > 0:\n",
    "    tf.config.experimental.set_memory_growth(physical_devices[0], True)\n",
    "from absl import app, flags, logging\n",
    "#from absl.flags import FLAGS\n",
    "import core.utils as utils\n",
    "from core.yolov4 import filter_boxes\n",
    "from tensorflow.python.saved_model import tag_constants\n",
    "from PIL import Image\n",
    "import cv2\n",
    "import numpy as np\n",
    "from tensorflow.compat.v1 import ConfigProto\n",
    "from tensorflow.compat.v1 import InteractiveSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# flags.DEFINE_string('framework', 'tf', '(tf, tflite, trt')\n",
    "# flags.DEFINE_string('weights', './checkpoints/yolov4-416',\n",
    "#                     'path to weights file')\n",
    "# flags.DEFINE_integer('size', 416, 'resize images to')\n",
    "# flags.DEFINE_boolean('tiny', False, 'yolo or yolo-tiny')\n",
    "# flags.DEFINE_string('model', 'yolov4', 'yolov3 or yolov4')\n",
    "# flags.DEFINE_string('image', './data/kite.jpg', 'path to input image')\n",
    "# flags.DEFINE_string('output', 'result.png', 'path to output image')\n",
    "# flags.DEFINE_float('iou', 0.45, 'iou threshold')\n",
    "# flags.DEFINE_float('score', 0.25, 'score threshold')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Parameters:\n",
    "    pass\n",
    "FLAGS = Parameters()\n",
    "FLAGS.framework = 'tf'\n",
    "FLAGS.weights = './checkpoints/yolov4-416'\n",
    "FLAGS.size = 416\n",
    "FLAGS.tiny = False\n",
    "FLAGS.model = 'yolov4'\n",
    "FLAGS.image = './data/girl.png'\n",
    "FLAGS.output = 'result.png'\n",
    "FLAGS.iou = 0.45\n",
    "FLAGS.score = 0.25\n",
    "\n",
    "if FLAGS.framework == 'tflite':\n",
    "    interpreter = tf.lite.Interpreter(model_path=FLAGS.weights)\n",
    "    interpreter.allocate_tensors()\n",
    "    input_details = interpreter.get_input_details()\n",
    "    output_details = interpreter.get_output_details()\n",
    "    print(input_details)\n",
    "    print(output_details)\n",
    "else:\n",
    "    saved_model_loaded = tf.saved_model.load(FLAGS.weights, tags=[tag_constants.SERVING])\n",
    "    infer = saved_model_loaded.signatures['serving_default']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(_argv):\n",
    "    config = ConfigProto()\n",
    "    config.gpu_options.allow_growth = True\n",
    "    session = InteractiveSession(config=config)\n",
    "    STRIDES, ANCHORS, NUM_CLASS, XYSCALE = utils.load_config(FLAGS)\n",
    "    input_size = FLAGS.size\n",
    "    image_path = FLAGS.image\n",
    "\n",
    "    original_image = cv2.imread(image_path)\n",
    "    original_image = cv2.cvtColor(original_image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    # image_data = utils.image_preprocess(np.copy(original_image), [input_size, input_size])\n",
    "    image_data = cv2.resize(original_image, (input_size, input_size))\n",
    "    image_data = image_data / 255.\n",
    "    # image_data = image_data[np.newaxis, ...].astype(np.float32)\n",
    "\n",
    "    images_data = []\n",
    "    for i in range(1):\n",
    "        images_data.append(image_data)\n",
    "    images_data = np.asarray(images_data).astype(np.float32)\n",
    "\n",
    "    if FLAGS.framework == 'tflite':\n",
    "        \n",
    "        interpreter.set_tensor(input_details[0]['index'], images_data)\n",
    "        interpreter.invoke()\n",
    "        pred = [interpreter.get_tensor(output_details[i]['index']) for i in range(len(output_details))]\n",
    "        if FLAGS.model == 'yolov3' and FLAGS.tiny == True:\n",
    "            boxes, pred_conf = filter_boxes(pred[1], pred[0], score_threshold=0.25, input_shape=tf.constant([input_size, input_size]))\n",
    "        else:\n",
    "            boxes, pred_conf = filter_boxes(pred[0], pred[1], score_threshold=0.25, input_shape=tf.constant([input_size, input_size]))\n",
    "    else:\n",
    "        batch_data = tf.constant(images_data)\n",
    "        pred_bbox = infer(batch_data)\n",
    "        for key, value in pred_bbox.items():\n",
    "            boxes = value[:, :, 0:4]\n",
    "            pred_conf = value[:, :, 4:]\n",
    "\n",
    "    boxes, scores, classes, valid_detections = tf.image.combined_non_max_suppression(\n",
    "        boxes=tf.reshape(boxes, (tf.shape(boxes)[0], -1, 1, 4)),\n",
    "        scores=tf.reshape(\n",
    "            pred_conf, (tf.shape(pred_conf)[0], -1, tf.shape(pred_conf)[-1])),\n",
    "        max_output_size_per_class=50,\n",
    "        max_total_size=50,\n",
    "        iou_threshold=FLAGS.iou,\n",
    "        score_threshold=FLAGS.score\n",
    "    )\n",
    "    pred_bbox = [boxes.numpy(), scores.numpy(), classes.numpy(), valid_detections.numpy()]\n",
    "    image = utils.draw_bbox(original_image, pred_bbox)\n",
    "    # image = utils.draw_bbox(image_data*255, pred_bbox)\n",
    "    image = Image.fromarray(image.astype(np.uint8))\n",
    "#     image.show()\n",
    "    image = cv2.cvtColor(np.array(image), cv2.COLOR_BGR2RGB)\n",
    "    cv2.imwrite(FLAGS.output, image)\n",
    "    return pred_bbox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9140522480010986\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "try:\n",
    "    t1 = time.time()\n",
    "    bboxes = main(0)\n",
    "    t2 = time.time()\n",
    "    print(t2 - t1)\n",
    "except SystemExit:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50, 4)\n",
      "[0.99512494 0.67152756 0.44780234 0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.        ]\n",
      "[ 0. 56. 67.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n"
     ]
    }
   ],
   "source": [
    "boxes, scores, classes, valid_tetections = bboxes[0][0], bboxes[1][0], bboxes[2][0], bboxes[3][0]\n",
    "print(boxes.shape)\n",
    "print(scores)\n",
    "print(classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  0.  20. 666. 777.]\n",
      " [223.   7. 452. 144.]\n",
      " [317.  48. 461. 233.]]\n",
      "[0.99512494 0.67152756 0.44780234]\n",
      "4\n"
     ]
    }
   ],
   "source": [
    "print(boxes[:valid_tetections])\n",
    "print(scores[:valid_tetections])\n",
    "print(len(valid_tetections.tobytes()))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
